{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"\u2708\ufe0f DataJet \u00b6 DataJet is a Data Dependency Graph Framework and Executor with the following features: Lazy: Evaluate and return only the data you need Efficient: DataJet doesn't get in the way of performance Declarative: Declare Data Dependencies and transformations explicitly, using plain python Dependency-Free: Just Python. Installation \u00b6 Install via pip from PyPi: pip install datajet Usage \u00b6 Usage is simple: from datajet import execute datajet_map = { \"dollars\": [3.99, 10.47, 18.95, 15.16,], \"units\": [1, 3, 5, 4,], \"prices\": lambda dollars, units: [d/u for d, u in zip(dollars, units)], \"average_price\": lambda prices: sum(prices) / len(prices) * 1000 // 10 / 100 } execute(datajet_map, fields=['prices', 'average_price']) # Result: # {'prices': [3.99, 3.49, 3.79, 3.79], 'average_price': 3.76} Look at What is DataJet to understand more, or jump straight into the tutorial .","title":"Home"},{"location":"#datajet","text":"DataJet is a Data Dependency Graph Framework and Executor with the following features: Lazy: Evaluate and return only the data you need Efficient: DataJet doesn't get in the way of performance Declarative: Declare Data Dependencies and transformations explicitly, using plain python Dependency-Free: Just Python.","title":"\u2708\ufe0f DataJet"},{"location":"#installation","text":"Install via pip from PyPi: pip install datajet","title":"Installation"},{"location":"#usage","text":"Usage is simple: from datajet import execute datajet_map = { \"dollars\": [3.99, 10.47, 18.95, 15.16,], \"units\": [1, 3, 5, 4,], \"prices\": lambda dollars, units: [d/u for d, u in zip(dollars, units)], \"average_price\": lambda prices: sum(prices) / len(prices) * 1000 // 10 / 100 } execute(datajet_map, fields=['prices', 'average_price']) # Result: # {'prices': [3.99, 3.49, 3.79, 3.79], 'average_price': 3.76} Look at What is DataJet to understand more, or jump straight into the tutorial .","title":"Usage"},{"location":"api/","text":"API \u00b6 Execute \u00b6 datajet.execute \u00b6 Execute the resolvers in a data_map to return values for fields requested. Parameters: data_map ( Union[dict, datajet._datamap.DataJetMap] ) \u2013 A data_map fields ( list ) \u2013 A list of fields to return from the data map. context ( dict ) \u2013 A dict of values to send to the data map as context. Source code in datajet/datajet.py def execute ( data_map : Union [ dict , DataJetMap ], fields : list , context : dict = None ) -> dict : \"\"\"Execute the resolvers in a data_map to return values for `fields` requested. Args: data_map: A data_map fields: A list of fields to return from the data map. context: A dict of values to send to the data map as context. \"\"\" if isinstance ( data_map , DataJetMap ): data_map = data_map . data_map if context is not None : data_map = copy . copy ( data_map ) data_map . update ( context ) data_map = _normalize_data_map ( data_map ) if not _is_valid_normalized_data_map ( data_map ): msg = _normalized_data_map_validation_error ( data_map ) raise ValueError ( msg ) dependencies_for_each_field = [ _get_dependencies ( data_map , field ) for field in fields ] results = {} for possible_dependency_paths_for_specific_field in dependencies_for_each_field : possible_dependency_paths_for_specific_field = sorted ( possible_dependency_paths_for_specific_field , key = lambda x : len ( x ) ) for dependency_path_for_specific_field in possible_dependency_paths_for_specific_field : for dependency in reversed ( dependency_path_for_specific_field ): if dependency in results : continue for d in data_map [ dependency ]: inputs = d [ IN ] if all ( input_ in results for input_ in inputs ): f = d [ F ] try : result = f ( * [ results [ in_ ] for in_ in inputs ]) except RuntimeResolutionException : continue else : results [ dependency ] = result break else : # none of the paths to the dependency had inputs in the context and succeeded # so, break out of 2nd for loop and start a different `dependency_path_for_specific_field` break else : # break out of loop over possible paths if all dependencies in `dependency_path_for_specific_field` are resolved break else : raise RuntimeResolutionException for to_delete in set ( results ) . difference ( fields ): results . pop ( to_delete ) return results DataJetMap \u00b6 datajet.DataJetMap \u00b6 Source code in datajet/_datamap.py class DataJetMap ( object ): def __init__ ( self ): self . _map : dict = {} def register ( self , output : Optional [ str ] = None , inputs : Optional [ List [ str ]] = None ): \"\"\"Decorator function to register the decorated function as a part of this datamap. Args: output: The output DataPoint identifier for the decorated function. Defaults to the function name. inputs: The DataPoint identifiers for the inputs into the resolver. Defaults to the names of the arguments of the decorated function. Example: from datajet import DataJetMap data_map = DataJetMap() @data_map.register() def sales(): return 4 @data_map.register() def units(): return 2 @data_map.register() def price(sales, units): return sales/units data_map.data_map {'sales': [{'in': [], 'f': <function __main__.sales()>}], 'units': [{'in': [], 'f': <function __main__.units()>}], 'price': [{'in': ['sales', 'units'], 'f': <function __main__.price(sales, units)>}]} \"\"\" def func ( f : Callable ): key = output if output is not None else f . __name__ resolver_list = self . _map . setdefault ( key , []) if inputs is not None : to_append = { IN : inputs , F : f } else : to_append = { F : f } resolver_list . append ( to_append ) return func @property def data_map ( self ): return _normalize_data_map ( self . _map ) register ( self , output = None , inputs = None ) \u00b6 Decorator function to register the decorated function as a part of this datamap. Parameters: output ( Optional[str] ) \u2013 The output DataPoint identifier for the decorated function. Defaults to the function name. inputs ( Optional[List[str]] ) \u2013 The DataPoint identifiers for the inputs into the resolver. Defaults to the names of the arguments of the decorated function. Examples: from datajet import DataJetMap data_map = DataJetMap() @data_map.register() def sales(): return 4 @data_map.register() def units(): return 2 @data_map.register() def price(sales, units): return sales/units data_map.data_map {'sales': [{'in': [], 'f': }], 'units': [{'in': [], 'f': }], 'price': [{'in': ['sales', 'units'], 'f': }]} Source code in datajet/_datamap.py def register ( self , output : Optional [ str ] = None , inputs : Optional [ List [ str ]] = None ): \"\"\"Decorator function to register the decorated function as a part of this datamap. Args: output: The output DataPoint identifier for the decorated function. Defaults to the function name. inputs: The DataPoint identifiers for the inputs into the resolver. Defaults to the names of the arguments of the decorated function. Example: from datajet import DataJetMap data_map = DataJetMap() @data_map.register() def sales(): return 4 @data_map.register() def units(): return 2 @data_map.register() def price(sales, units): return sales/units data_map.data_map {'sales': [{'in': [], 'f': <function __main__.sales()>}], 'units': [{'in': [], 'f': <function __main__.units()>}], 'price': [{'in': ['sales', 'units'], 'f': <function __main__.price(sales, units)>}]} \"\"\" def func ( f : Callable ): key = output if output is not None else f . __name__ resolver_list = self . _map . setdefault ( key , []) if inputs is not None : to_append = { IN : inputs , F : f } else : to_append = { F : f } resolver_list . append ( to_append ) return func Common resolvers \u00b6 datajet.common_resolvers.required_from_context \u00b6 Returns a resolver function that anticipates and requires input from the context. Use this as a \"placeholder\" in your datamap for context. Notes Prefer to use this function over raising a RuntimeResolutionException , as the engine that powers datajet.execute will optimize the search for a valid data-path (to increase performance) if a context_input is not given in the context. Source code in datajet/common_resolvers.py def required_from_context (): \"\"\"Returns a resolver function that anticipates and requires input from the context. Use this as a \"placeholder\" in your datamap for context. Notes: Prefer to use this function over raising a `RuntimeResolutionException`, as the engine that powers `datajet.execute` will optimize the search for a valid data-path (to increase performance) if a `context_input` is not given in the context. \"\"\" return _REQUIRED_FROM_CONTEXT datajet.common_resolvers.alias \u00b6 Returns a resolver function that acts as an alias to the node . Parameters: datapoint ( Hashable ) \u2013 The datapoint to alias. Notes Use the resolver output from this function to pass through the data from one node directly to another. Source code in datajet/common_resolvers.py def alias ( datapoint : Hashable ) -> List [ dict ]: \"\"\"Returns a resolver function that acts as an alias to the `node`. Args: datapoint: The datapoint to alias. Notes: Use the resolver output from this function to pass through the data from one node directly to another. \"\"\" return [{ IN : [ datapoint ], F : lambda x : x }] datajet.common_resolvers.dict_resolver \u00b6 Returns a resolver function that looks up the resulting value from d corresponding with the key output from input_datapoint . Parameters: input_datapoint ( Hashable ) \u2013 The datapoint that will be looked up in d to find the value returned from this resolver. d ( dict ) \u2013 The dict to lookup input_datapoint in. Notes The resolver will raise RuntimeResolutionException if the key is not found in the dict at \"resolution time.\" Source code in datajet/common_resolvers.py def dict_resolver ( input_datapoint : Hashable , d : dict ) -> List [ dict ]: \"\"\"Returns a resolver function that looks up the resulting value from `d` corresponding with the key output from `input_datapoint`. Args: input_datapoint: The datapoint that will be looked up in `d` to find the value returned from this resolver. d: The dict to lookup `input_datapoint` in. Notes: The resolver will raise RuntimeResolutionException if the key is not found in the dict at \"resolution time.\" \"\"\" def _f ( key ): try : return d [ key ] except KeyError : raise RuntimeResolutionException return [{ IN : [ input_datapoint ], F : _f }] Exceptions \u00b6 datajet.exceptions.RuntimeResolutionException \u00b6 A exception was raised during execution of the datamap for fields. Usage Raise this exception inside a resolver to indicate to datajet that the resolution of the resolver is not possible with the given inputs. DataJet will catch and ignore this exception and proceed with other valid execution paths that return the requested fields in the DataMap if they exist. Source code in datajet/exceptions.py class RuntimeResolutionException ( Exception ): \"\"\"A exception was raised during execution of the datamap for fields. Usage: Raise this exception inside a resolver to indicate to datajet that the resolution of the resolver is not possible with the given inputs. DataJet will catch and ignore this exception and proceed with other valid execution paths that return the requested fields in the DataMap if they exist. \"\"\" datajet.exceptions.PlanNotFoundError \u00b6 A valid plan was not found in the datamap to return the fields requested. Notes This is typically raised by DataJet when it is no viable paths (paths that do not raise RuntimeResolutionException ) exist in the datamap to return the requested fields. Source code in datajet/exceptions.py class PlanNotFoundError ( ValueError ): \"\"\"A valid plan was not found in the datamap to return the fields requested. Notes: This is typically raised by DataJet when it is no viable paths (paths that do not raise `RuntimeResolutionException`) exist in the datamap to return the requested fields. \"\"\" Keywords \u00b6","title":"API"},{"location":"api/#api","text":"","title":"API"},{"location":"api/#execute","text":"","title":"Execute"},{"location":"api/#datajetexecute","text":"Execute the resolvers in a data_map to return values for fields requested. Parameters: data_map ( Union[dict, datajet._datamap.DataJetMap] ) \u2013 A data_map fields ( list ) \u2013 A list of fields to return from the data map. context ( dict ) \u2013 A dict of values to send to the data map as context. Source code in datajet/datajet.py def execute ( data_map : Union [ dict , DataJetMap ], fields : list , context : dict = None ) -> dict : \"\"\"Execute the resolvers in a data_map to return values for `fields` requested. Args: data_map: A data_map fields: A list of fields to return from the data map. context: A dict of values to send to the data map as context. \"\"\" if isinstance ( data_map , DataJetMap ): data_map = data_map . data_map if context is not None : data_map = copy . copy ( data_map ) data_map . update ( context ) data_map = _normalize_data_map ( data_map ) if not _is_valid_normalized_data_map ( data_map ): msg = _normalized_data_map_validation_error ( data_map ) raise ValueError ( msg ) dependencies_for_each_field = [ _get_dependencies ( data_map , field ) for field in fields ] results = {} for possible_dependency_paths_for_specific_field in dependencies_for_each_field : possible_dependency_paths_for_specific_field = sorted ( possible_dependency_paths_for_specific_field , key = lambda x : len ( x ) ) for dependency_path_for_specific_field in possible_dependency_paths_for_specific_field : for dependency in reversed ( dependency_path_for_specific_field ): if dependency in results : continue for d in data_map [ dependency ]: inputs = d [ IN ] if all ( input_ in results for input_ in inputs ): f = d [ F ] try : result = f ( * [ results [ in_ ] for in_ in inputs ]) except RuntimeResolutionException : continue else : results [ dependency ] = result break else : # none of the paths to the dependency had inputs in the context and succeeded # so, break out of 2nd for loop and start a different `dependency_path_for_specific_field` break else : # break out of loop over possible paths if all dependencies in `dependency_path_for_specific_field` are resolved break else : raise RuntimeResolutionException for to_delete in set ( results ) . difference ( fields ): results . pop ( to_delete ) return results","title":"datajet.execute"},{"location":"api/#datajetmap","text":"","title":"DataJetMap"},{"location":"api/#datajetdatajetmap","text":"Source code in datajet/_datamap.py class DataJetMap ( object ): def __init__ ( self ): self . _map : dict = {} def register ( self , output : Optional [ str ] = None , inputs : Optional [ List [ str ]] = None ): \"\"\"Decorator function to register the decorated function as a part of this datamap. Args: output: The output DataPoint identifier for the decorated function. Defaults to the function name. inputs: The DataPoint identifiers for the inputs into the resolver. Defaults to the names of the arguments of the decorated function. Example: from datajet import DataJetMap data_map = DataJetMap() @data_map.register() def sales(): return 4 @data_map.register() def units(): return 2 @data_map.register() def price(sales, units): return sales/units data_map.data_map {'sales': [{'in': [], 'f': <function __main__.sales()>}], 'units': [{'in': [], 'f': <function __main__.units()>}], 'price': [{'in': ['sales', 'units'], 'f': <function __main__.price(sales, units)>}]} \"\"\" def func ( f : Callable ): key = output if output is not None else f . __name__ resolver_list = self . _map . setdefault ( key , []) if inputs is not None : to_append = { IN : inputs , F : f } else : to_append = { F : f } resolver_list . append ( to_append ) return func @property def data_map ( self ): return _normalize_data_map ( self . _map )","title":"datajet.DataJetMap"},{"location":"api/#datajet._datamap.DataJetMap.register","text":"Decorator function to register the decorated function as a part of this datamap. Parameters: output ( Optional[str] ) \u2013 The output DataPoint identifier for the decorated function. Defaults to the function name. inputs ( Optional[List[str]] ) \u2013 The DataPoint identifiers for the inputs into the resolver. Defaults to the names of the arguments of the decorated function. Examples: from datajet import DataJetMap data_map = DataJetMap() @data_map.register() def sales(): return 4 @data_map.register() def units(): return 2 @data_map.register() def price(sales, units): return sales/units data_map.data_map {'sales': [{'in': [], 'f': }], 'units': [{'in': [], 'f': }], 'price': [{'in': ['sales', 'units'], 'f': }]} Source code in datajet/_datamap.py def register ( self , output : Optional [ str ] = None , inputs : Optional [ List [ str ]] = None ): \"\"\"Decorator function to register the decorated function as a part of this datamap. Args: output: The output DataPoint identifier for the decorated function. Defaults to the function name. inputs: The DataPoint identifiers for the inputs into the resolver. Defaults to the names of the arguments of the decorated function. Example: from datajet import DataJetMap data_map = DataJetMap() @data_map.register() def sales(): return 4 @data_map.register() def units(): return 2 @data_map.register() def price(sales, units): return sales/units data_map.data_map {'sales': [{'in': [], 'f': <function __main__.sales()>}], 'units': [{'in': [], 'f': <function __main__.units()>}], 'price': [{'in': ['sales', 'units'], 'f': <function __main__.price(sales, units)>}]} \"\"\" def func ( f : Callable ): key = output if output is not None else f . __name__ resolver_list = self . _map . setdefault ( key , []) if inputs is not None : to_append = { IN : inputs , F : f } else : to_append = { F : f } resolver_list . append ( to_append ) return func","title":"register()"},{"location":"api/#common-resolvers","text":"","title":"Common resolvers"},{"location":"api/#datajetcommon_resolversrequired_from_context","text":"Returns a resolver function that anticipates and requires input from the context. Use this as a \"placeholder\" in your datamap for context. Notes Prefer to use this function over raising a RuntimeResolutionException , as the engine that powers datajet.execute will optimize the search for a valid data-path (to increase performance) if a context_input is not given in the context. Source code in datajet/common_resolvers.py def required_from_context (): \"\"\"Returns a resolver function that anticipates and requires input from the context. Use this as a \"placeholder\" in your datamap for context. Notes: Prefer to use this function over raising a `RuntimeResolutionException`, as the engine that powers `datajet.execute` will optimize the search for a valid data-path (to increase performance) if a `context_input` is not given in the context. \"\"\" return _REQUIRED_FROM_CONTEXT","title":"datajet.common_resolvers.required_from_context"},{"location":"api/#datajetcommon_resolversalias","text":"Returns a resolver function that acts as an alias to the node . Parameters: datapoint ( Hashable ) \u2013 The datapoint to alias. Notes Use the resolver output from this function to pass through the data from one node directly to another. Source code in datajet/common_resolvers.py def alias ( datapoint : Hashable ) -> List [ dict ]: \"\"\"Returns a resolver function that acts as an alias to the `node`. Args: datapoint: The datapoint to alias. Notes: Use the resolver output from this function to pass through the data from one node directly to another. \"\"\" return [{ IN : [ datapoint ], F : lambda x : x }]","title":"datajet.common_resolvers.alias"},{"location":"api/#datajetcommon_resolversdict_resolver","text":"Returns a resolver function that looks up the resulting value from d corresponding with the key output from input_datapoint . Parameters: input_datapoint ( Hashable ) \u2013 The datapoint that will be looked up in d to find the value returned from this resolver. d ( dict ) \u2013 The dict to lookup input_datapoint in. Notes The resolver will raise RuntimeResolutionException if the key is not found in the dict at \"resolution time.\" Source code in datajet/common_resolvers.py def dict_resolver ( input_datapoint : Hashable , d : dict ) -> List [ dict ]: \"\"\"Returns a resolver function that looks up the resulting value from `d` corresponding with the key output from `input_datapoint`. Args: input_datapoint: The datapoint that will be looked up in `d` to find the value returned from this resolver. d: The dict to lookup `input_datapoint` in. Notes: The resolver will raise RuntimeResolutionException if the key is not found in the dict at \"resolution time.\" \"\"\" def _f ( key ): try : return d [ key ] except KeyError : raise RuntimeResolutionException return [{ IN : [ input_datapoint ], F : _f }]","title":"datajet.common_resolvers.dict_resolver"},{"location":"api/#exceptions","text":"","title":"Exceptions"},{"location":"api/#datajetexceptionsruntimeresolutionexception","text":"A exception was raised during execution of the datamap for fields. Usage Raise this exception inside a resolver to indicate to datajet that the resolution of the resolver is not possible with the given inputs. DataJet will catch and ignore this exception and proceed with other valid execution paths that return the requested fields in the DataMap if they exist. Source code in datajet/exceptions.py class RuntimeResolutionException ( Exception ): \"\"\"A exception was raised during execution of the datamap for fields. Usage: Raise this exception inside a resolver to indicate to datajet that the resolution of the resolver is not possible with the given inputs. DataJet will catch and ignore this exception and proceed with other valid execution paths that return the requested fields in the DataMap if they exist. \"\"\"","title":"datajet.exceptions.RuntimeResolutionException"},{"location":"api/#datajetexceptionsplannotfounderror","text":"A valid plan was not found in the datamap to return the fields requested. Notes This is typically raised by DataJet when it is no viable paths (paths that do not raise RuntimeResolutionException ) exist in the datamap to return the requested fields. Source code in datajet/exceptions.py class PlanNotFoundError ( ValueError ): \"\"\"A valid plan was not found in the datamap to return the fields requested. Notes: This is typically raised by DataJet when it is no viable paths (paths that do not raise `RuntimeResolutionException`) exist in the datamap to return the requested fields. \"\"\"","title":"datajet.exceptions.PlanNotFoundError"},{"location":"api/#keywords","text":"","title":"Keywords"},{"location":"core-concepts/","text":"Core Concepts \u00b6 DataPoint \u00b6 A DataPoint is a single \"piece\" of data that may be related to other datapoints via being an input to or output of resolvers . Each key in a DataMap corresponds to a single datapoint. A datapoint in other contexts is sometimes called an \"attribute\", \"property\", or \"field\" -- they are essentially the nodes on the data dependency graph. Note A DataPoint is not necessarily a single value , it may be a series of data values, or a column of a dataset, or even a whole data table. The important part is that it is a unit of data that is derived in total from other units of data. Resolver \u00b6 Resolvers are python functions that establish relationships between datapoints. A resolver relates the input datapoints, which correspond to arguments to the function, to the datapoint represented by the output of the function. Resolvers work with lambda or regular python functions defined with def , as well as functions cached with functools.lru_cache . DataMap \u00b6 A DataMap is a declaration of all datapoints and associated dependency datapoints & resolvers in a system. A DataMap is declared as a regular python dict that must adhere to a particular schema--see DataMap Reference for more.","title":"Core Concepts"},{"location":"core-concepts/#core-concepts","text":"","title":"Core Concepts"},{"location":"core-concepts/#datapoint","text":"A DataPoint is a single \"piece\" of data that may be related to other datapoints via being an input to or output of resolvers . Each key in a DataMap corresponds to a single datapoint. A datapoint in other contexts is sometimes called an \"attribute\", \"property\", or \"field\" -- they are essentially the nodes on the data dependency graph. Note A DataPoint is not necessarily a single value , it may be a series of data values, or a column of a dataset, or even a whole data table. The important part is that it is a unit of data that is derived in total from other units of data.","title":"DataPoint"},{"location":"core-concepts/#resolver","text":"Resolvers are python functions that establish relationships between datapoints. A resolver relates the input datapoints, which correspond to arguments to the function, to the datapoint represented by the output of the function. Resolvers work with lambda or regular python functions defined with def , as well as functions cached with functools.lru_cache .","title":"Resolver"},{"location":"core-concepts/#datamap","text":"A DataMap is a declaration of all datapoints and associated dependency datapoints & resolvers in a system. A DataMap is declared as a regular python dict that must adhere to a particular schema--see DataMap Reference for more.","title":"DataMap"},{"location":"datamap-reference/","text":"DataMap Reference \u00b6 Dependencies between datapoints in DataJet are declared in DataMaps, which are python dictionaries with a single key for each datapoint in the system. Normalized DataMaps \u00b6 A normalized DataMap is the most verbose and regularized format of a DataMap. There are other acceptable schemas for datamaps that are accepted by datajet.execute (see DataMap Shortcuts ), however, it is helpful to first understand DataMaps in their normalized form to understand what a DataMap is declaring. A DataMap is a normal python dict . Each key in the dictionary corresponds with a single datapoint in the dependency graph of the system. The dict key is the representation of the datapoint, you should choose a key with meaning. You could perhaps use tuples or namedtuples or dataclasses to specifically represent each datapoint to avoid conflicts. The value corresponding to each key must be a list or tuple . The two are interchangeable. Each element of the list or tuple represents one potential \"path\" to the datapoint represented by the dict key. A path is a way to derive that datapoint--it is defined by a function and inputs to that function. Each path is represented by a python dict with the keys \"f\" and \"in\" . The value of \"f\" is a python function (called a \"resolver function\"), and the value of \"in\" must be a list of other datapoints defined as keys in the DataMap. To derive the datapoint, the function at \"f\" will be executed with the inputs from \"in\" passed to it as positional arguments. Example Normalized DataMap \u00b6 def is_below_freezing(temp, scale): if scale == \"fahrenheit\": return temp < 32 if scale == \"celsius\": return temp < 0 raise ValueError data_map = { \"temperature\": [{\"in\": [], \"f\": lambda: 39}], \"temperature_scale\": [{\"in\": [], \"f\": lambda: \"fahrenheit\"}], \"people_have_coats_on\": [{\"in\": [], \"f\": lambda: True}], \"temp_is_likely_below_freezing\": [ {\"in\": [\"temperature\", \"temperature_scale\"], \"f\": is_below_freezing}, {\"in\": [\"people_have_coats_on\"], \"f\": lambda x: x}, ] } In the above example, the datapoints \"temperature\" , \"temperature_scale\" , and \"people_have_coats_on\" are all \"static\" in the sense that those datapoints are not dependent on any other datapoints in the DataMap. \"temp_is_likely_below_freezing\" has 2 potential ways to calculate it -- one that uses \"temperature\" and \"temperature_scale\" , and one that derives whether the \"temp_is_likely_below_freezing\" from the \"people_have_coats_on\" datapoint. Here, the two paths to \"temp_is_likely_below_freezing\" is somewhat contrived, but one may want to specify two paths to a single datapoint in the case when it is not clear at \"DataMap declaration time\" what datapoints will have enough information to be calculated. You can tell datajet that a datapoint is expected to be provided at \"execute time\" by using the required_by_context common resolver DataMap Requirements \u00b6 In addition to the above schema, datajet validates each DataMap for the following rules: * Each datapoint listed in an \"in\" list must also be represented as a top-level key in the DataMap * No extraneous keys, aside from \"in\" and \"f\" , can be present in any \"path\" dicts for any datapoints. * The arity (number of arguments) for each resolver function at each \"f\" key must be equal to the length of the list at the corresponding \"in\" key, or else it must take a variable number of positional arguments that is compatable with the length of the list. DataMap shortcuts \u00b6 The \"normalized data map\" is the internal datajet representation of a DataMap, and an acceptable schema for declaring DataMaps in your code. However, it is quite verbose. DataJet will allow several \"shortcuts\" when specifying your DataMap, to ease DataMap declaration: Defining a single path with a dict \u00b6 If you have only one path to a datapoint, you can forgo the list or tuple in the dict value and just write the dict that represents a single path. data_map_with_1_path = { \"last-name\": {\"in\": [\"full-name\"], \"f\": lambda fn: fn.split(\" \")[-1]} } Infering inputs from resolver arguments \u00b6 If the string representation of the arguments of your resolver function match other datapoints, you can forgo specifying the \"in\" parameter, and only specify your function (as in \"al_east_teams_sorted\" below). DataJet will infer the input datapoint(s) by matching the string arguments to other keys in the DataMap. data_map = { \"al_east_teams\": {\"f\": lambda: [\"Yankees\", \"Rays\", \"Blue Jays\", \"Orioles\", \"Red Sox\"]}, \"al_east_teams_sorted\": {\"f\": lambda al_east_teams: list(sorted(al_east_teams)}) } DataJet will also accept a DataMap if you forgo the dict altogether and just give a resolver function as the value: data_map = { \"al_east_teams\": lambda: [\"Yankees\", \"Rays\", \"Blue Jays\", \"Orioles\", \"Red Sox\"], \"al_east_teams_sorted\": lambda al_east_teams: list(sorted(al_east_teams)) } If the string representations of each argument to the resolver function are not found as other datapoints (keys) in the DataMap, the DataMap is invalid and datajet.execute will error. Defining Constants \u00b6 In general, you can specify any constant DataPoints in your DataMap by simply declaring the constant as the dict value for the DataPoint Key. DataJet will infer if the constant does not conform to the expected dict or list schemas listed above, and treat the value as a constant if it does not. data_map = { \"plate_appearance_results\": [\"hit\", \"walk\", \"hit\", \"ground out\"], \"n_at_bats\": lambda plate_appearance_results: len([x for x in plate_appearance_results if x not in ('walk', 'hbp', 'sac')]), \"n_hits\": lambda plate_appearance_results: len([x for x in plate_appearance_results if x == 'hit']), 'batting_avg': lambda n_hits, n_at_bats: n_hits/n_at_bats } In the datamap above, \"plate_appearance_results\" is declared as a constant. The DataJetMap decorator class \u00b6 Some users may feel more comfortable with decorating resolver functions to \"register\" them in a data map. To facilitate this pattern, DataJet offers the DataJetMap class: from datajet import DataJetMap, execute data_map = DataJetMap() @data_map.register() def sales(): return 4 @data_map.register() def units(sales): return 2 * sales @data_map.register() def price(sales, units): return sales/units execute(data_map, fields=['price']) {'price': 0.5}","title":"DataMap Reference"},{"location":"datamap-reference/#datamap-reference","text":"Dependencies between datapoints in DataJet are declared in DataMaps, which are python dictionaries with a single key for each datapoint in the system.","title":"DataMap Reference"},{"location":"datamap-reference/#normalized-datamaps","text":"A normalized DataMap is the most verbose and regularized format of a DataMap. There are other acceptable schemas for datamaps that are accepted by datajet.execute (see DataMap Shortcuts ), however, it is helpful to first understand DataMaps in their normalized form to understand what a DataMap is declaring. A DataMap is a normal python dict . Each key in the dictionary corresponds with a single datapoint in the dependency graph of the system. The dict key is the representation of the datapoint, you should choose a key with meaning. You could perhaps use tuples or namedtuples or dataclasses to specifically represent each datapoint to avoid conflicts. The value corresponding to each key must be a list or tuple . The two are interchangeable. Each element of the list or tuple represents one potential \"path\" to the datapoint represented by the dict key. A path is a way to derive that datapoint--it is defined by a function and inputs to that function. Each path is represented by a python dict with the keys \"f\" and \"in\" . The value of \"f\" is a python function (called a \"resolver function\"), and the value of \"in\" must be a list of other datapoints defined as keys in the DataMap. To derive the datapoint, the function at \"f\" will be executed with the inputs from \"in\" passed to it as positional arguments.","title":"Normalized DataMaps"},{"location":"datamap-reference/#example-normalized-datamap","text":"def is_below_freezing(temp, scale): if scale == \"fahrenheit\": return temp < 32 if scale == \"celsius\": return temp < 0 raise ValueError data_map = { \"temperature\": [{\"in\": [], \"f\": lambda: 39}], \"temperature_scale\": [{\"in\": [], \"f\": lambda: \"fahrenheit\"}], \"people_have_coats_on\": [{\"in\": [], \"f\": lambda: True}], \"temp_is_likely_below_freezing\": [ {\"in\": [\"temperature\", \"temperature_scale\"], \"f\": is_below_freezing}, {\"in\": [\"people_have_coats_on\"], \"f\": lambda x: x}, ] } In the above example, the datapoints \"temperature\" , \"temperature_scale\" , and \"people_have_coats_on\" are all \"static\" in the sense that those datapoints are not dependent on any other datapoints in the DataMap. \"temp_is_likely_below_freezing\" has 2 potential ways to calculate it -- one that uses \"temperature\" and \"temperature_scale\" , and one that derives whether the \"temp_is_likely_below_freezing\" from the \"people_have_coats_on\" datapoint. Here, the two paths to \"temp_is_likely_below_freezing\" is somewhat contrived, but one may want to specify two paths to a single datapoint in the case when it is not clear at \"DataMap declaration time\" what datapoints will have enough information to be calculated. You can tell datajet that a datapoint is expected to be provided at \"execute time\" by using the required_by_context common resolver","title":"Example Normalized DataMap"},{"location":"datamap-reference/#datamap-requirements","text":"In addition to the above schema, datajet validates each DataMap for the following rules: * Each datapoint listed in an \"in\" list must also be represented as a top-level key in the DataMap * No extraneous keys, aside from \"in\" and \"f\" , can be present in any \"path\" dicts for any datapoints. * The arity (number of arguments) for each resolver function at each \"f\" key must be equal to the length of the list at the corresponding \"in\" key, or else it must take a variable number of positional arguments that is compatable with the length of the list.","title":"DataMap Requirements"},{"location":"datamap-reference/#datamap-shortcuts","text":"The \"normalized data map\" is the internal datajet representation of a DataMap, and an acceptable schema for declaring DataMaps in your code. However, it is quite verbose. DataJet will allow several \"shortcuts\" when specifying your DataMap, to ease DataMap declaration:","title":"DataMap shortcuts"},{"location":"datamap-reference/#defining-a-single-path-with-a-dict","text":"If you have only one path to a datapoint, you can forgo the list or tuple in the dict value and just write the dict that represents a single path. data_map_with_1_path = { \"last-name\": {\"in\": [\"full-name\"], \"f\": lambda fn: fn.split(\" \")[-1]} }","title":"Defining a single path with a dict"},{"location":"datamap-reference/#infering-inputs-from-resolver-arguments","text":"If the string representation of the arguments of your resolver function match other datapoints, you can forgo specifying the \"in\" parameter, and only specify your function (as in \"al_east_teams_sorted\" below). DataJet will infer the input datapoint(s) by matching the string arguments to other keys in the DataMap. data_map = { \"al_east_teams\": {\"f\": lambda: [\"Yankees\", \"Rays\", \"Blue Jays\", \"Orioles\", \"Red Sox\"]}, \"al_east_teams_sorted\": {\"f\": lambda al_east_teams: list(sorted(al_east_teams)}) } DataJet will also accept a DataMap if you forgo the dict altogether and just give a resolver function as the value: data_map = { \"al_east_teams\": lambda: [\"Yankees\", \"Rays\", \"Blue Jays\", \"Orioles\", \"Red Sox\"], \"al_east_teams_sorted\": lambda al_east_teams: list(sorted(al_east_teams)) } If the string representations of each argument to the resolver function are not found as other datapoints (keys) in the DataMap, the DataMap is invalid and datajet.execute will error.","title":"Infering inputs from resolver arguments"},{"location":"datamap-reference/#defining-constants","text":"In general, you can specify any constant DataPoints in your DataMap by simply declaring the constant as the dict value for the DataPoint Key. DataJet will infer if the constant does not conform to the expected dict or list schemas listed above, and treat the value as a constant if it does not. data_map = { \"plate_appearance_results\": [\"hit\", \"walk\", \"hit\", \"ground out\"], \"n_at_bats\": lambda plate_appearance_results: len([x for x in plate_appearance_results if x not in ('walk', 'hbp', 'sac')]), \"n_hits\": lambda plate_appearance_results: len([x for x in plate_appearance_results if x == 'hit']), 'batting_avg': lambda n_hits, n_at_bats: n_hits/n_at_bats } In the datamap above, \"plate_appearance_results\" is declared as a constant.","title":"Defining Constants"},{"location":"datamap-reference/#the-datajetmap-decorator-class","text":"Some users may feel more comfortable with decorating resolver functions to \"register\" them in a data map. To facilitate this pattern, DataJet offers the DataJetMap class: from datajet import DataJetMap, execute data_map = DataJetMap() @data_map.register() def sales(): return 4 @data_map.register() def units(sales): return 2 * sales @data_map.register() def price(sales, units): return sales/units execute(data_map, fields=['price']) {'price': 0.5}","title":"The DataJetMap decorator class"},{"location":"installation/","text":"Installation \u00b6 Install Python 3.8 or later, if you don't already have it. Install datajet from PyPi $ pip install datajet Now it is time to get started","title":"Installation"},{"location":"installation/#installation","text":"Install Python 3.8 or later, if you don't already have it. Install datajet from PyPi $ pip install datajet Now it is time to get started","title":"Installation"},{"location":"quickstart/","text":"Quickstart \u00b6 new text","title":"Quickstart"},{"location":"quickstart/#quickstart","text":"new text","title":"Quickstart"},{"location":"tutorial/","text":"Tutorial \u00b6 For this tutorial, we suppose you are a teacher who has given an exam, and is now comparing the exam results on different grading scales. The grades for the exams are numbers between 0-100, and you are experimenting with different cutoffs for letter grades, and different definitions of \"passing\" letter grades. Letter Grades \u00b6 To start out, let's write a simple data map that defines a resolver to derive \"exam_letter_grades\" from \"exam_scores\" and \"letter_grade_cutoffs\" . exam_scores = [98, 73, 65, 95, 88, 58, 40, 94] default_letter_grade_cutoffs = {90: \"A\", 80: \"B\", 70: \"C\", 60: \"D\", 0: \"F\"} data_map = { \"exam_scores\": exam_scores, \"letter_grade_cutoffs\": default_letter_grade_cutoffs, \"exam_letter_grades\": lambda exam_scores, letter_grade_cutoffs: [ letter_grade_cutoffs[max((cut for cut in letter_grade_cutoffs if cut < score))] for score in exam_scores ] } Now we can import datajet and get the letter grades for our exam scores: import datajet datajet.execute(data_map, fields=[\"exam_letter_grades\"]) # Result # {'exam_letter_grades': ['A', 'C', 'D', 'A', 'B', 'F', 'F', 'A']} Great, easy enough. Let's add a pass/fail component to the datamap now, and find how many are passing: data_map = { \"exam_scores\": exam_scores, \"letter_grade_cutoffs\": default_letter_grade_cutoffs, \"exam_letter_grades\": lambda exam_scores, letter_grade_cutoffs: [ letter_grade_cutoffs[max((cut for cut in letter_grade_cutoffs if cut < score))] for score in exam_scores ], # We define passing as having a \"A\", \"B\", \"C\" or \"D\" grade \"passing_grades\": set([\"A\", \"B\", \"C\", \"D\"]), \"exam_pass_fail_grades\": lambda passing_grades, exam_letter_grades: [grade in passing_grades for grade in exam_letter_grades], \"n_passing\": {\"in\": [\"exam_pass_fail_grades\"], \"f\": sum}, } Let's see how many students passed: datajet.execute(data_map, fields=[\"n_passing\"]) # Result {'n_passing': 6} Note we can also return several different fields: datajet.execute(data_map, fields=[\"pct_passing\",\"exam_letter_grades\",\"exam_pass_fail_grades\"]) # Result {'exam_letter_grades': ['A', 'C', 'D', 'A', 'B', 'F', 'F', 'A'], 'exam_pass_fail_grades': [True, True, True, True, True, False, False, True], 'n_passing': 6} Overwrite DataMap at execute time \u00b6 Say you wanted to calculate the n_passing on a different grading scale, this time with a pass/fail cutoff of 75: execute( data_map, context={ \"letter_grade_cutoffs\": {75: \"Pass\", 0: \"Fail\"}, \"passing_grades\": [\"Pass\"] }, fields=[\"n_passing\",\"exam_letter_grades\",\"exam_pass_fail_grades\"] ) # Result {'exam_letter_grades': ['Pass', 'Fail', 'Fail', 'Pass', 'Pass', 'Fail', 'Fail', 'Pass'], 'exam_pass_fail_grades': [True, False, False, True, True, False, False, True], 'n_passing': 4} Explanation \u00b6 In this example, the context field overrides the default values we declared in our original datamap for \"letter_grade_cutoffs\" and \"passing_grades\" . We set \"letter_grade_cutoffs\" to {75: \"Pass\"} , which, according to the logic we originally declared in DataPoint \"exam_letter_grades\" , means that any exam with a score >=75 will be given the \"letter grade\" of \"Pass\" , while others will receive the \"letter grade\" \"F\" (derived from the default value we declared for the DataPoint \"lowest_grade\" ). We also tell datajet via the context parameter that we accept only \"Pass\" as a \"passing grade.\" You can see the logic a little better if you ask for a few more fields: execute( data_map, context={ \"letter_grade_cutoffs\": {75: \"Pass\", 0: \"Fail\"}, \"passing_grades\": [\"Pass\"] }, fields=[\"n_passing\",\"exam_letter_grades\",\"exam_pass_fail_grades\",\"exam_scores\"] ) {'exam_scores': [98, 73, 65, 95, 88, 58, 40, 94], 'exam_letter_grades': ['Pass', 'Fail', 'Fail', 'Pass', 'Pass', 'Fail', 'Fail', 'Pass'], 'exam_pass_fail_grades': [True, False, False, True, True, False, False, True], 'n_passing': 4} Find number of passing exams when you only have letter grades to start \u00b6 Say, you started with a set of letter grades, and wanted to know the pct passing, taking either As, Bs, or Cs as \"passing\". execute( data_map, context={ \"exam_letter_grades\": (\"A\"*8)+(\"B\"*18)+(\"C\"*14)+(\"D\"*13)+(\"F\"*5), \"passing_grades\": \"ABC\" }, fields=['n_passing'] ) {'n_passing': 40} In this case, datajet bypasses calculating the \"exam_letter_grades\" from \"exam_scores\" because we gave it the letter grades as constants, and thus removed the dependency of \"exam_letter_grades\" on \"exam_scores\" that existed in our original DataMap declaration. DataJet takes the \"exam_letter_grades\" as-is from our context , and compares those grades with the \"passing_grades\" we also specified in the context, then uses the logic originally declared in the DataMap for \"exam_pass_fail_grades\" and \"n_passing\" to tell us that 40 of the exams had passing grades.","title":"Tutorial"},{"location":"tutorial/#tutorial","text":"For this tutorial, we suppose you are a teacher who has given an exam, and is now comparing the exam results on different grading scales. The grades for the exams are numbers between 0-100, and you are experimenting with different cutoffs for letter grades, and different definitions of \"passing\" letter grades.","title":"Tutorial"},{"location":"tutorial/#letter-grades","text":"To start out, let's write a simple data map that defines a resolver to derive \"exam_letter_grades\" from \"exam_scores\" and \"letter_grade_cutoffs\" . exam_scores = [98, 73, 65, 95, 88, 58, 40, 94] default_letter_grade_cutoffs = {90: \"A\", 80: \"B\", 70: \"C\", 60: \"D\", 0: \"F\"} data_map = { \"exam_scores\": exam_scores, \"letter_grade_cutoffs\": default_letter_grade_cutoffs, \"exam_letter_grades\": lambda exam_scores, letter_grade_cutoffs: [ letter_grade_cutoffs[max((cut for cut in letter_grade_cutoffs if cut < score))] for score in exam_scores ] } Now we can import datajet and get the letter grades for our exam scores: import datajet datajet.execute(data_map, fields=[\"exam_letter_grades\"]) # Result # {'exam_letter_grades': ['A', 'C', 'D', 'A', 'B', 'F', 'F', 'A']} Great, easy enough. Let's add a pass/fail component to the datamap now, and find how many are passing: data_map = { \"exam_scores\": exam_scores, \"letter_grade_cutoffs\": default_letter_grade_cutoffs, \"exam_letter_grades\": lambda exam_scores, letter_grade_cutoffs: [ letter_grade_cutoffs[max((cut for cut in letter_grade_cutoffs if cut < score))] for score in exam_scores ], # We define passing as having a \"A\", \"B\", \"C\" or \"D\" grade \"passing_grades\": set([\"A\", \"B\", \"C\", \"D\"]), \"exam_pass_fail_grades\": lambda passing_grades, exam_letter_grades: [grade in passing_grades for grade in exam_letter_grades], \"n_passing\": {\"in\": [\"exam_pass_fail_grades\"], \"f\": sum}, } Let's see how many students passed: datajet.execute(data_map, fields=[\"n_passing\"]) # Result {'n_passing': 6} Note we can also return several different fields: datajet.execute(data_map, fields=[\"pct_passing\",\"exam_letter_grades\",\"exam_pass_fail_grades\"]) # Result {'exam_letter_grades': ['A', 'C', 'D', 'A', 'B', 'F', 'F', 'A'], 'exam_pass_fail_grades': [True, True, True, True, True, False, False, True], 'n_passing': 6}","title":"Letter Grades"},{"location":"tutorial/#overwrite-datamap-at-execute-time","text":"Say you wanted to calculate the n_passing on a different grading scale, this time with a pass/fail cutoff of 75: execute( data_map, context={ \"letter_grade_cutoffs\": {75: \"Pass\", 0: \"Fail\"}, \"passing_grades\": [\"Pass\"] }, fields=[\"n_passing\",\"exam_letter_grades\",\"exam_pass_fail_grades\"] ) # Result {'exam_letter_grades': ['Pass', 'Fail', 'Fail', 'Pass', 'Pass', 'Fail', 'Fail', 'Pass'], 'exam_pass_fail_grades': [True, False, False, True, True, False, False, True], 'n_passing': 4}","title":"Overwrite DataMap at execute time"},{"location":"tutorial/#explanation","text":"In this example, the context field overrides the default values we declared in our original datamap for \"letter_grade_cutoffs\" and \"passing_grades\" . We set \"letter_grade_cutoffs\" to {75: \"Pass\"} , which, according to the logic we originally declared in DataPoint \"exam_letter_grades\" , means that any exam with a score >=75 will be given the \"letter grade\" of \"Pass\" , while others will receive the \"letter grade\" \"F\" (derived from the default value we declared for the DataPoint \"lowest_grade\" ). We also tell datajet via the context parameter that we accept only \"Pass\" as a \"passing grade.\" You can see the logic a little better if you ask for a few more fields: execute( data_map, context={ \"letter_grade_cutoffs\": {75: \"Pass\", 0: \"Fail\"}, \"passing_grades\": [\"Pass\"] }, fields=[\"n_passing\",\"exam_letter_grades\",\"exam_pass_fail_grades\",\"exam_scores\"] ) {'exam_scores': [98, 73, 65, 95, 88, 58, 40, 94], 'exam_letter_grades': ['Pass', 'Fail', 'Fail', 'Pass', 'Pass', 'Fail', 'Fail', 'Pass'], 'exam_pass_fail_grades': [True, False, False, True, True, False, False, True], 'n_passing': 4}","title":"Explanation"},{"location":"tutorial/#find-number-of-passing-exams-when-you-only-have-letter-grades-to-start","text":"Say, you started with a set of letter grades, and wanted to know the pct passing, taking either As, Bs, or Cs as \"passing\". execute( data_map, context={ \"exam_letter_grades\": (\"A\"*8)+(\"B\"*18)+(\"C\"*14)+(\"D\"*13)+(\"F\"*5), \"passing_grades\": \"ABC\" }, fields=['n_passing'] ) {'n_passing': 40} In this case, datajet bypasses calculating the \"exam_letter_grades\" from \"exam_scores\" because we gave it the letter grades as constants, and thus removed the dependency of \"exam_letter_grades\" on \"exam_scores\" that existed in our original DataMap declaration. DataJet takes the \"exam_letter_grades\" as-is from our context , and compares those grades with the \"passing_grades\" we also specified in the context, then uses the logic originally declared in the DataMap for \"exam_pass_fail_grades\" and \"n_passing\" to tell us that 40 of the exams had passing grades.","title":"Find number of passing exams when you only have letter grades to start"},{"location":"what-is-datajet/","text":"What is datajet? \u00b6 Datajet is a framework for working with complex dependencies in data. It allows the user to declare all datapoints and immediate dependencies of a system in a DataMap , then query the dependency graph for any included datapoints, given a set of inputs. Datajet in effect \"abstracts away\" function calls, allowing the user to \"just give inputs and get outputs\" to a system of datapoints and dependencies. import datajet datamap = { \"dollars\": datajet.common_resolvers.required_from_context(), \"units\": datajet.common_resolvers.required_from_context(), \"prices\": lambda dollars, units: [d/u for d, u in zip(dollars, units)], \"average_price\": lambda prices: sum(prices) / len(prices) * 1000 // 10 / 100 } execute( datamap, fields=['average_price'], context={\"dollars\": [3.99, 10.47, 18.95,],\"units\": [1, 3, 5,]} ) {'average_price': 3.75}","title":"What Is Datajet?"},{"location":"what-is-datajet/#what-is-datajet","text":"Datajet is a framework for working with complex dependencies in data. It allows the user to declare all datapoints and immediate dependencies of a system in a DataMap , then query the dependency graph for any included datapoints, given a set of inputs. Datajet in effect \"abstracts away\" function calls, allowing the user to \"just give inputs and get outputs\" to a system of datapoints and dependencies. import datajet datamap = { \"dollars\": datajet.common_resolvers.required_from_context(), \"units\": datajet.common_resolvers.required_from_context(), \"prices\": lambda dollars, units: [d/u for d, u in zip(dollars, units)], \"average_price\": lambda prices: sum(prices) / len(prices) * 1000 // 10 / 100 } execute( datamap, fields=['average_price'], context={\"dollars\": [3.99, 10.47, 18.95,],\"units\": [1, 3, 5,]} ) {'average_price': 3.75}","title":"What is datajet?"},{"location":"user-guide/getting-started/","text":"lkasjdf","title":"Getting started"}]}